//! MMB exporter, which produces `.mmb` binary proof files from an
//! [`Environment`](crate::Environment) object.
use std::mem;
use std::io::{self, Write, Seek, SeekFrom};
use byteorder::{LE, ByteOrder, WriteBytesExt};
use mm0b_parser::MAX_BOUND_VARS;
use zerocopy::{AsBytes, U32, U64};
use crate::{
  Type, SortId, AtomId, AtomVec, TermKind, ThmKind,
  TermVec, ExprNode, ProofNode, StmtTrace, DeclKey, Modifiers,
  FrozenEnv, FileRef, LinedString, ErrorLevel};

#[allow(clippy::wildcard_imports)]
use mm0b_parser::{ProofCmd, UnifyCmd, cmd::*, write_cmd_bytes};

#[derive(Debug)]
struct Reorder<T=u32> {
  map: Box<[Option<T>]>,
  idx: u32,
}

impl<T> Reorder<T> {
  fn new(nargs: u32, len: usize, mut f: impl FnMut(u32) -> T) -> Reorder<T> {
    assert!(nargs as usize <= len);
    let mut map = Vec::with_capacity(len);
    map.extend((0..nargs).map(|i| Some(f(i))));
    map.resize_with(len, Default::default);
    let mut map: Box<[Option<T>]> = map.into();
    for i in 0..nargs {map[i as usize] = Some(f(i))}
    Reorder {map, idx: nargs}
  }
}

/// The main exporter structure. This keeps track of the underlying writer,
/// as well as tracking values that are written out of order.
pub struct Exporter<'a, W> {
  /// The name of the input file. This is only used in the debugging data.
  file: FileRef,
  /// The source text of the input file. This is only used in the debugging data.
  source: Option<&'a LinedString>,
  /// The input environment.
  env: &'a FrozenEnv,
  /// Error reporting.
  report: &'a mut dyn FnMut(ErrorLevel, &str),
  /// The underlying writer, which must support [`Seek`] because we write some parts
  /// of the file out of order. The [`BigBuffer`] wrapper can be used to equip a
  /// writer that doesn't support it with a [`Seek`] implementation.
  w: W,
  /// The current byte position of the writer.
  pos: u64,
  /// The calculated reorder maps for terms encountered so far (see [`Reorder`]).
  term_reord: TermVec<Option<Reorder>>,
  /// A list of "fixups", which are writes that have to occur in places other
  /// than the current writer location. We buffer these to avoid too many seeks
  /// of the underlying writer.
  fixups: Vec<(u64, Value)>,
}

impl<W: std::fmt::Debug> std::fmt::Debug for Exporter<'_, W> {
  fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
    f.debug_struct("Exporter")
      .field("file", &self.file)
      .field("source", &self.source)
      .field("env", &self.env)
      .field("w", &self.w)
      .field("pos", &self.pos)
      .field("term_reord", &self.term_reord)
      .field("fixups", &self.fixups)
      .finish()
  }
}

/// A chunk of data that needs to be written out of order.
#[derive(Debug)]
enum Value {
  /// A (little endian) 32 bit value
  U32(U32<LE>),
  /// A (little endian) 64 bit value
  U64(U64<LE>),
  /// An arbitrary length byte slice. (We could store everything like this but
  /// the `U32` and `U64` cases are common and this avoids some allocation.)
  Box(Box<[u8]>),
}

/// A type for a 32 bit fixup, representing a promise to write 32 bits at the stored
/// location. It is generated by [`fixup32`](Exporter::fixup32) method,
/// and it is marked `#[must_use]` because it should be consumed by
/// [`commit`](Fixup32::commit), which requires fulfilling the promise.
#[must_use] struct Fixup32(u64);

/// A type for a 64 bit fixup, representing a promise to write 64 bits at the stored
/// location. It is generated by [`fixup64`](Exporter::fixup64) method,
/// and it is marked `#[must_use]` because it should be consumed by
/// [`commit`](Fixup64::commit), which requires fulfilling the promise.
#[must_use] struct Fixup64(u64);

/// A type for an arbitrary size fixup, representing a promise to write some number of bytes
/// bits at the given location. It is generated by
/// [`fixup_large`](Exporter::fixup_large) method,
/// and it is marked `#[must_use]` because it should be consumed by
/// [`commit`](FixupLarge::commit), which requires fulfilling the promise.
#[must_use] struct FixupLarge(u64, Box<[u8]>);

impl Fixup32 {
  /// Write `val` to this fixup, closing it.
  fn commit_val<W: Write + Seek>(self, e: &mut Exporter<'_, W>, val: u32) {
    e.fixups.push((self.0, Value::U32(U32::new(val))))
  }
  /// Write the current position of the exporter to this fixup, closing it.
  fn commit<W: Write + Seek>(self, e: &mut Exporter<'_, W>) {
    let val = e.pos.try_into().expect("position out of range");
    self.commit_val(e, val)
  }
}

impl Fixup64 {
  /// Write `val` to this fixup, closing it.
  fn commit_val<W: Write + Seek>(self, e: &mut Exporter<'_, W>, val: u64) {
    e.fixups.push((self.0, Value::U64(U64::new(val))))
  }
  /// Write the current position of the exporter to this fixup, closing it.
  fn commit<W: Write + Seek>(self, e: &mut Exporter<'_, W>) {
    let val = e.pos;
    self.commit_val(e, val)
  }
  /// Drop the value, which has the effect of writing 0 to the original fixup.
  #[inline] fn cancel(self) { drop(self) }
}

impl std::ops::Deref for FixupLarge {
  type Target = [u8];
  fn deref(&self) -> &[u8] { &self.1 }
}
impl std::ops::DerefMut for FixupLarge {
  fn deref_mut(&mut self) -> &mut [u8] { &mut self.1 }
}

impl FixupLarge {
  /// Assume that the construction of the fixup is complete, and write the stored value.
  fn commit<W: Write + Seek>(self, e: &mut Exporter<'_, W>) {
    e.fixups.push((self.0, Value::Box(self.1)))
  }
}

impl<W: Write + Seek> Write for Exporter<'_, W> {
  fn write(&mut self, buf: &[u8]) -> io::Result<usize> {
    self.write_all(buf)?;
    Ok(buf.len())
  }
  fn write_all(&mut self, buf: &[u8]) -> io::Result<()> {
    self.pos += buf.len() as u64;
    self.w.write_all(buf)
  }
  fn flush(&mut self) -> io::Result<()> { self.w.flush() }
}

#[allow(clippy::too_many_arguments)]
fn write_expr_proof(
  env: &FrozenEnv,
  w: &mut impl Write,
  heap: &[ExprNode],
  store: &[ExprNode],
  reorder: &mut Reorder,
  vars: &mut Option<&mut Vec<AtomId>>,
  node: &ExprNode,
  save: bool
) -> io::Result<u32> {
  Ok(match *node {
    ExprNode::Ref(i) => match reorder.map[i] {
      None => {
        let n = write_expr_proof(env, w, heap, store, reorder, vars, &heap[i], true)?;
        reorder.map[i] = Some(n);
        n
      }
      Some(n) => {ProofCmd::Ref(n).write_to(w)?; n}
    }
    ExprNode::Dummy(a, s) => {
      if let Some(vec) = vars {vec.push(a)}
      ProofCmd::Dummy(s).write_to(w)?;
      (reorder.idx, reorder.idx += 1).0
    }
    ExprNode::App(tid, p) => {
      for e in env.term(tid).unpack_app(&store[p..]) {
        write_expr_proof(env, w, heap, store, reorder, vars, e, false)?;
      }
      ProofCmd::Term {tid, save}.write_to(w)?;
      if save { (reorder.idx, reorder.idx += 1).0 } else { 0 }
    }
  })
}

/// A wrapper around a writer that implements [`Write`]` + `[`Seek`] by internally buffering
/// all writes, writing to the underlying writer only once on [`Drop`].
#[derive(Debug)]
pub struct BigBuffer<W: Write> {
  buffer: io::Cursor<Vec<u8>>,
  w: W,
}

impl<W: Write> BigBuffer<W> {
  /// Creates a new buffer given an underlying writer.
  pub fn new(w: W) -> Self { Self {buffer: Default::default(), w} }
  /// Flushes the buffer to the underlying writer, consuming the result.
  /// (The [`Drop`] implementation will also do this, but this allows us
  /// to catch IO errors.)
  pub fn finish(mut self) -> io::Result<()> {
    self.w.write_all(&mem::take(self.buffer.get_mut()))
  }
}

impl<W: Write> Write for BigBuffer<W> {
  fn write(&mut self, buf: &[u8]) -> io::Result<usize> { self.buffer.write(buf) }
  fn flush(&mut self) -> io::Result<()> { self.buffer.flush() }
}

impl<W: Write> Seek for BigBuffer<W> {
  fn seek(&mut self, pos: SeekFrom) -> io::Result<u64> { self.buffer.seek(pos) }
}

impl<W: Write> Drop for BigBuffer<W> {
  fn drop(&mut self) {
    self.w.write_all(self.buffer.get_ref()).expect("write failed in Drop impl")
  }
}

struct NameData {
  name: AtomId,
  p_proof: u64,
}

#[derive(Default)]
struct VarData {
  p_vars: u64,
  vars: Vec<AtomId>,
}

#[allow(clippy::struct_field_names)]
struct IndexTemp {
  sort_names: Vec<NameData>,
  term_names: Vec<(NameData, VarData)>,
  /// The second `VarData` is the list of hypotheses
  thm_names: Vec<((NameData, VarData), VarData)>,
}

impl<'a, W: Write + Seek> Exporter<'a, W> {
  /// Construct a new [`Exporter`] from an input file `file` with text `source`,
  /// a source environment containing proved theorems, and output writer `w`.
  pub fn new(
    file: FileRef,
    source: Option<&'a LinedString>,
    env: &'a FrozenEnv,
    report: &'a mut dyn FnMut(ErrorLevel, &str),
    w: W
  ) -> Self {
    Self {
      term_reord: TermVec(Vec::with_capacity(env.terms().len())),
      file, source, env, report, w, pos: 0, fixups: vec![]
    }
  }

  fn write_u32(&mut self, n: u32) -> io::Result<()> {
    WriteBytesExt::write_u32::<LE>(self, n)
  }

  fn write_u64(&mut self, n: u64) -> io::Result<()> {
    WriteBytesExt::write_u64::<LE>(self, n)
  }

  fn write_str(&mut self, s: &'a [u8]) -> io::Result<()> {
    for &c in s {assert!(c != 0)}
    self.write_all(s)?;
    self.write_u8(0)
  }

  fn fixup32(&mut self) -> io::Result<Fixup32> {
    let f = Fixup32(self.pos);
    self.write_u32(0)?;
    Ok(f)
  }

  fn fixup64(&mut self) -> io::Result<Fixup64> {
    let f = Fixup64(self.pos);
    self.write_u64(0)?;
    Ok(f)
  }

  fn fixup_large(&mut self, size: usize) -> io::Result<FixupLarge> {
    let f = FixupLarge(self.pos, vec![0; size].into());
    self.write_all(&f)?;
    Ok(f)
  }

  #[inline]
  fn align_to(&mut self, n: u8) -> io::Result<u64> {
    #[allow(clippy::cast_possible_truncation)] // actual truncation
    let i = n.wrapping_sub(self.pos as u8) & (n - 1);
    self.write_all(&vec![0; i.into()])?;
    Ok(self.pos)
  }

  #[inline]
  fn write_sort_deps(&mut self, bound: bool, sort: SortId, deps: u64) -> io::Result<()> {
    self.write_u64(u64::from(bound) << 63 | u64::from(sort.0) << 56 | deps)
  }

  #[inline]
  fn write_term_header(header: &mut [u8], nargs: u16, sort: SortId, has_def: bool, p_term: u32) {
    LE::write_u16(&mut header[0..], nargs);
    header[2] = sort.0 | if has_def {0x80} else {0};
    LE::write_u32(&mut header[4..], p_term);
  }

  fn write_binders<T>(&mut self, args: &[(T, Type)]) -> io::Result<()> {
    let mut bv = 1;
    for (_, ty) in args {
      match *ty {
        Type::Bound(s) => {
          assert!(bv < (1 << MAX_BOUND_VARS), "more than {MAX_BOUND_VARS} bound variables");
          self.write_sort_deps(true, s, bv)?;
          bv *= 2;
        }
        Type::Reg(s, deps) => self.write_sort_deps(false, s, deps)?,
      }
    }
    Ok(())
  }

  fn write_expr_unify(&mut self,
    heap: &[ExprNode],
    store: &[ExprNode],
    reorder: &mut Reorder,
    node: &ExprNode,
    save: &mut Vec<usize>
  ) -> io::Result<()> {
    macro_rules! commit {($n:expr) => {
      for i in save.drain(..) {reorder.map[i] = Some($n)}
    }}
    match *node {
      ExprNode::Ref(i) => match reorder.map[i] {
        None => {
          save.push(i);
          self.write_expr_unify(heap, store, reorder, &heap[i], save)?
        }
        Some(n) => {
          UnifyCmd::Ref(n).write_to(self)?;
          commit!(n)
        }
      }
      ExprNode::Dummy(_, s) => {
        commit!(reorder.idx); reorder.idx += 1;
        UnifyCmd::Dummy(s).write_to(self)?
      }
      ExprNode::App(tid, p) => {
        if save.is_empty() {
          UnifyCmd::Term {tid, save: false}.write_to(self)?
        } else {
          commit!(reorder.idx); reorder.idx += 1;
          UnifyCmd::Term {tid, save: true}.write_to(self)?
        }
        for e in self.env.term(tid).unpack_app(&store[p..]) {
          self.write_expr_unify(heap, store, reorder, e, save)?
        }
      }
    }
    Ok(())
  }

  #[allow(clippy::too_many_arguments)]
  fn write_proof(&self, w: &mut impl Write,
    heap: &[ProofNode],
    store: &[ProofNode],
    reorder: &mut Reorder,
    hyps: &[u32],
    node: &ProofNode,
    save: bool
  ) -> io::Result<u32> {
    Ok(match *node {
      ProofNode::Ref(i) => match reorder.map[i] {
        None => {
          let n = self.write_proof(w, heap, store, reorder, hyps, &heap[i], true)?;
          reorder.map[i] = Some(n);
          n
        }
        Some(n) => {ProofCmd::Ref(n).write_to(w)?; n}
      }
      ProofNode::Dummy(_, s) => {
        ProofCmd::Dummy(s).write_to(w)?;
        (reorder.idx, reorder.idx += 1).0
      }
      ProofNode::Term(term, p) => {
        for e in self.env.term(term).unpack_term(&store[p..]) {
          self.write_proof(w, heap, store, reorder, hyps, e, false)?;
        }
        ProofCmd::Term {tid: term, save}.write_to(w)?;
        if save {(reorder.idx, reorder.idx += 1).0} else {0}
      }
      ProofNode::Hyp(n, _) => {
        ProofCmd::Ref(hyps[n]).write_to(w)?;
        hyps[n]
      }
      ProofNode::Thm(thm, p) => {
        let (res, args, hs) = self.env.thm(thm).unpack_thm(&store[p..]);
        for e in hs {self.write_proof(w, heap, store, reorder, hyps, e, false)?;}
        for e in args {self.write_proof(w, heap, store, reorder, hyps, e, false)?;}
        self.write_proof(w, heap, store, reorder, hyps, res, false)?;
        ProofCmd::Thm {tid: thm, save}.write_to(w)?;
        if save {(reorder.idx, reorder.idx += 1).0} else {0}
      }
      ProofNode::Conv(p) => {
        let (e1, c, p) = ProofNode::unpack_conv(&store[p..]);
        self.write_proof(w, heap, store, reorder, hyps, e1, false)?;
        self.write_proof(w, heap, store, reorder, hyps, p, false)?;
        ProofCmd::Conv.write_to(w)?;
        self.write_conv(w, heap, store, reorder, hyps, c)?;
        if save {
          ProofCmd::Save.write_to(w)?;
          (reorder.idx, reorder.idx += 1).0
        } else {0}
      }
      ProofNode::Refl(_) |
      ProofNode::Sym(_) |
      ProofNode::Cong {..} |
      ProofNode::Unfold {..} => unreachable!(),
    })
  }

  fn write_conv(&self, w: &mut impl Write,
    heap: &[ProofNode],
    store: &[ProofNode],
    reorder: &mut Reorder,
    hyps: &[u32],
    node: &ProofNode,
  ) -> io::Result<()> {
    match *node {
      ProofNode::Ref(i) => match reorder.map[i] {
        None => {
          let e = &heap[i];
          match e {
            ProofNode::Refl(_) | ProofNode::Ref(_) =>
              self.write_conv(w, heap, store, reorder, hyps, e)?,
            _ => {
              ProofCmd::ConvCut.write_to(w)?;
              self.write_conv(w, heap, store, reorder, hyps, e)?;
              ProofCmd::ConvSave.write_to(w)?;
              reorder.map[i] = Some(reorder.idx);
              reorder.idx += 1;
            }
          };
        }
        Some(n) => ProofCmd::Ref(n).write_to(w)?,
      }
      ProofNode::Dummy(_, _) |
      ProofNode::Term {..} |
      ProofNode::Hyp(_, _) |
      ProofNode::Thm {..} |
      ProofNode::Conv(_) => unreachable!(),
      ProofNode::Refl(_) => ProofCmd::Refl.write_to(w)?,
      ProofNode::Sym(c) => {
        ProofCmd::Sym.write_to(w)?;
        self.write_conv(w, heap, store, reorder, hyps, &store[c])?;
      }
      ProofNode::Cong(term, p) => {
        ProofCmd::Cong.write_to(w)?;
        for a in self.env.term(term).unpack_term(&store[p..]) {
          self.write_conv(w, heap, store, reorder, hyps, a)?
        }
      }
      ProofNode::Unfold(term, p) => {
        let (sub_lhs, c, _) = self.env.term(term).unpack_unfold(&store[p..]);
        self.write_proof(w, heap, store, reorder, hyps, sub_lhs, false)?;
        ProofCmd::Unfold.write_to(w)?;
        self.write_conv(w, heap, store, reorder, hyps, c)?;
      }
    }
    Ok(())
  }

  #[inline]
  fn write_thm_header(header: &mut [u8], nargs: u16, p_thm: u32) {
    LE::write_u16(&mut header[0..], nargs);
    LE::write_u32(&mut header[4..], p_thm);
  }

  /// Perform the actual export. If `index` is true, also output the
  /// (optional) debugging table to the file.
  ///
  /// This does not finalize all writes. [`finish`] should be called after this
  /// to write the outstanding fixups.
  ///
  /// [`finish`]: Self::finish
  pub fn run(&mut self, index: bool) -> io::Result<()> {
    self.write_all(&MM0B_MAGIC)?; // magic
    let num_sorts = self.env.sorts().len();
    assert!(num_sorts <= 128, "too many sorts (max 128)");
    #[allow(clippy::cast_possible_truncation)]
    self.write_all(&[MM0B_VERSION, num_sorts as u8, 0, 0])?; // two bytes reserved
    let num_terms = self.env.terms().len();
    self.write_u32(num_terms.try_into().expect("too many terms"))?; // num_terms
    let num_thms = self.env.thms().len();
    self.write_u32(num_thms.try_into().expect("too many thms"))?; // num_thms
    let p_terms = self.fixup32()?;
    let p_thms = self.fixup32()?;
    let p_proof = self.fixup32()?;
    self.write_u32(0)?;
    let p_index = self.fixup64()?;

    // sort data
    self.write_all(&self.env.sorts().iter().map(|s| s.mods.bits()).collect::<Vec<u8>>())?;

    // term header
    self.align_to(8)?; p_terms.commit(self);
    let mut term_header = self.fixup_large(num_terms * 8)?;
    for (head, t) in term_header.chunks_exact_mut(8).zip(&self.env.terms().0) {
      let nargs: u16 = t.args.len().try_into().expect("term has more than 65536 args");
      Self::write_term_header(head, nargs, t.ret.0,
        matches!(t.kind, TermKind::Def(_)),
        self.align_to(8)?.try_into().expect("address too large"));
      self.write_binders(&t.args)?;
      self.write_sort_deps(false, t.ret.0, t.ret.1)?;
      let reorder = if let TermKind::Def(val) = &t.kind {
        let expr = val.as_ref().unwrap_or_else(||
          panic!("def {} missing value", self.env.data()[t.atom].name()));
        let mut reorder = Reorder::new(nargs.into(), expr.heap.len(), |i| i);
        self.write_expr_unify(&expr.heap, &expr.store, &mut reorder, expr.head(), &mut vec![])?;
        self.write_u8(0)?;
        Some(reorder)
      } else { None };
      self.term_reord.push(reorder);
    }
    term_header.commit(self);

    // theorem header
    self.align_to(8)?; p_thms.commit(self);
    let mut thm_header = self.fixup_large(num_thms * 8)?;
    for (head, t) in thm_header.chunks_exact_mut(8).zip(&self.env.thms().0) {
      let nargs = t.args.len().try_into().expect("theorem has more than 65536 args");
      Self::write_thm_header(head, nargs,
        self.align_to(8)?.try_into().expect("address too large"));
      self.write_binders(&t.args)?;
      let mut reorder = Reorder::new(nargs.into(), t.heap.len(), |i| i);
      let save = &mut vec![];
      self.write_expr_unify(&t.heap, &t.store, &mut reorder, &t.ret, save)?;
      for (_, h) in t.hyps.iter().rev() {
        UnifyCmd::Hyp.write_to(self)?;
        self.write_expr_unify(&t.heap, &t.store, &mut reorder, h, save)?;
      }
      self.write_u8(0)?;
    }
    thm_header.commit(self);

    // main body (proofs of theorems)
    p_proof.commit(self);
    let vec = &mut vec![];
    let mut index_temp = if index {
      Some(IndexTemp {
        sort_names: Vec::with_capacity(num_sorts),
        term_names: Vec::with_capacity(num_terms),
        thm_names: Vec::with_capacity(num_thms),
      })
    } else { None };
    for s in self.env.stmts() {
      match *s {
        StmtTrace::Sort(a) => {
          if let Some(temp) = &mut index_temp {
            temp.sort_names.push(NameData { name: a, p_proof: self.pos });
          }
          write_cmd_bytes(self, STMT_SORT, &[])?
        }
        StmtTrace::Decl(a) => {
          match self.env.data()[a].decl().expect("expected a term/thm") {
            DeclKey::Term(t) => {
              let td = self.env.term(t);
              let vars = &mut index_temp.as_mut().map(|temp| {
                let vars = td.args.iter().map(|p| p.0.unwrap_or(AtomId::UNDER)).collect();
                temp.term_names.push((
                  NameData {name: a, p_proof: self.pos},
                  VarData {p_vars: 0, vars}
                ));
                // Safety: we just pushed to term_names
                unsafe { &mut temp.term_names.last_mut().unwrap_unchecked().1.vars }
              });
              match &td.kind {
                TermKind::Term => write_cmd_bytes(self, STMT_TERM, &[])?,
                TermKind::Def(None) => panic!("def {} missing definition", self.env.data()[td.atom].name()),
                TermKind::Def(Some(expr)) => {
                  #[allow(clippy::cast_possible_truncation)] // no truncation
                  let nargs = td.args.len() as u32;
                  let mut reorder = Reorder::new(nargs, expr.heap.len(), |i| i);
                  write_expr_proof(self.env, vec, &expr.heap, &expr.store,
                    &mut reorder, vars, expr.head(), false)?;
                  vec.write_u8(0)?;
                  let cmd = STMT_DEF | if td.vis == Modifiers::LOCAL {STMT_LOCAL} else {0};
                  write_cmd_bytes(self, cmd, vec)?;
                  vec.clear();
                }
              }
            }
            DeclKey::Thm(t) => {
              let td = self.env.thm(t);
              let vars = &mut index_temp.as_mut().map(|temp| {
                temp.thm_names.push(((
                  NameData {name: a, p_proof: self.pos},
                  VarData {p_vars: 0, vars: td.args.iter()
                    .map(|p| p.0.unwrap_or(AtomId::UNDER)).collect()}),
                  VarData {p_vars: 0, vars: td.hyps.iter()
                    .map(|p| p.0.unwrap_or(AtomId::UNDER)).collect()},
                ));
                // Safety: we just pushed to thm_names
                unsafe { &mut temp.thm_names.last_mut().unwrap_unchecked().1.vars }
              });
              #[allow(clippy::cast_possible_truncation)] // no truncation
              let nargs = td.args.len() as u32;
              let cmd = match &td.kind {
                ThmKind::Axiom | ThmKind::Thm(None) => {
                  let mut reorder = Reorder::new(nargs, td.heap.len(), |i| i);
                  for (_, h) in &*td.hyps {
                    write_expr_proof(self.env, vec, &td.heap, &td.store,
                      &mut reorder, vars, h, false)?;
                    ProofCmd::Hyp.write_to(vec)?;
                    reorder.idx += 1;
                  }
                  write_expr_proof(self.env, vec, &td.heap, &td.store,
                    &mut reorder, vars, &td.ret, false)?;
                  if matches!(td.kind, ThmKind::Axiom) {
                    STMT_AXIOM
                  } else {
                    ProofCmd::Sorry.write_to(vec)?;
                    (self.report)(ErrorLevel::Warning, &format!(
                      "theorem {} contains sorry", self.env.data()[td.atom].name()));
                    STMT_THM | if td.vis == Modifiers::PUB {0} else {STMT_LOCAL}
                  }
                }
                ThmKind::Thm(Some(pf)) => {
                  let mut reorder = Reorder::new(nargs, pf.heap.len(), |i| i);
                  let mut ehyps = Vec::with_capacity(pf.hyps.len());
                  for h in &*pf.hyps {
                    let e = match *h.deref(&pf.heap) {
                      ProofNode::Hyp(_, i) => &pf.store[i],
                      _ => unreachable!()
                    };
                    self.write_proof(vec, &pf.heap, &pf.store, &mut reorder, &ehyps, e, false)?;
                    ProofCmd::Hyp.write_to(vec)?;
                    ehyps.push(reorder.idx);
                    reorder.idx += 1;
                  }
                  self.write_proof(vec, &pf.heap, &pf.store,
                    &mut reorder, &ehyps, pf.head(), false)?;
                  STMT_THM | if td.vis == Modifiers::PUB {0} else {STMT_LOCAL}
                }
              };
              vec.write_u8(0)?;
              write_cmd_bytes(self, cmd, vec)?;
              vec.clear();
            }
          }
        }
        StmtTrace::Global(_) |
        StmtTrace::OutputString(_) => {}
      }
    }
    self.write_u8(0)?;

    // debugging index
    if let Some(IndexTemp { mut sort_names, mut term_names, mut thm_names }) = index_temp {
      assert_eq!(sort_names.len(), num_sorts);
      assert_eq!(term_names.len(), num_terms);
      assert_eq!(thm_names.len(), num_thms);

      let mut atom_pos = AtomVec(self.env.data().enum_iter().map(|(_, ad)| -> io::Result<_> {
        if ad.sort().is_some() || ad.decl().is_some() {
          let pos = self.pos;
          self.write_str(ad.name())?;
          Ok(pos)
        } else { Ok(0) }
      }).collect::<io::Result<Vec<u64>>>()?);

      macro_rules! decls {() => {
        term_names.iter_mut().chain(thm_names.iter_mut().map(|p| &mut p.0))
      }}
      let mut add_atom = |a| if atom_pos[a] == 0 {
        atom_pos[a] = self.pos;
        self.write_str(self.env.data()[a].name())
      } else { Ok(()) };
      for &a in decls!().flat_map(|n| &n.1.vars) { add_atom(a)? }
      for &a in thm_names.iter().flat_map(|n| &n.1.vars) { add_atom(a)? }

      self.align_to(8)?;
      let mut write_vd = |vd: &mut VarData| -> io::Result<()> {
        vd.p_vars = self.pos;
        self.write_u64(vd.vars.len() as u64)?;
        for &a in &vd.vars { self.write_u64(atom_pos[a])? }
        Ok(())
      };
      for (_, vd) in &mut term_names { write_vd(vd)? }
      for ((_, vd), hs) in &mut thm_names { write_vd(vd)?; write_vd(hs)? }

      let p_names = self.pos;
      for n in sort_names.iter_mut().chain(decls!().map(|(n, _)| n)) {
        self.write_u64(n.p_proof)?;
        self.write_u64(atom_pos[n.name])?;
      }

      let p_vars = self.pos;
      for (_, vd) in decls!() { self.write_u64(vd.p_vars)? }

      let p_hyps = self.pos;
      for (_, hs) in &thm_names { self.write_u64(hs.p_vars)? }

      p_index.commit(self);
      let index = [(INDEX_NAME, p_names), (INDEX_VAR_NAME, p_vars), (INDEX_HYP_NAME, p_hyps)];
      self.write_u64(index.len() as u64)?;
      for (name, ptr) in &index {
        self.write_all(name)?;
        self.write_u32(0)?;
        self.write_u64(*ptr)?;
      }
    } else {
      p_index.cancel();
      self.write_u32(0)?; // padding
    }
    Ok(())
  }

  /// Finalize the outstanding fixups, and flush the writer. Consumes self since we're done.
  pub fn finish(self) -> io::Result<()> {
    let Self {mut w, fixups, ..} = self;
    for (pos, f) in fixups {
      w.seek(SeekFrom::Start(pos))?;
      match f {
        Value::U32(n) => w.write_all(n.as_bytes())?,
        Value::U64(n) => w.write_all(n.as_bytes())?,
        Value::Box(buf) => w.write_all(&buf)?,
      }
    }
    w.flush()
  }
}
